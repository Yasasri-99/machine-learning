{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOkNsXHaNfrOghzteOsEf3M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yasasri-99/machine-learning/blob/main/Lematization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8v6B8fdD3fH7",
        "outputId": "af862c51-a014-4531-c95f-9d76ebbd2321"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer=WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "c7oW_D3R4J2l"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''Once there lived a greedy man in a small town. (He was very rich, and he loved gold and all things fancy.\n",
        " But he loved his daughter more than anything. One day, he chanced upon a fairy. The fairy’s hair was caught in a few tree branches.\n",
        "  He helped her out, but as his greediness took over, he realised that he had an opportunity to become richer by asking for a wish in return (by helping her out).\n",
        " The fairy granted him a wish. He said, “All that I touch should turn to gold.” And his wish was granted by the grateful fairy.'''\n",
        " \n",
        "punctuations = \"?:!.,;\"\n"
      ],
      "metadata": {
        "id": "xd_dL2Fu4gec"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize,word_tokenize"
      ],
      "metadata": {
        "id": "xx8C5pzj4gfk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatizeSentence(text):\n",
        " token_words=word_tokenize(text)\n",
        " print(token_words)\n",
        " lemma_sentence=[]\n",
        " for word in token_words:\n",
        "  lemma_sentence.append(wordnet_lemmatizer.lemmatize(word))\n",
        "  lemma_sentence.append(\"\")\n",
        " return\"\".join(lemma_sentence)"
      ],
      "metadata": {
        "id": "txiVmdr85bY0"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x= lemmatizeSentence(text)\n",
        "print(\"Sentence after Lematization : \", x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4V32ctFK6uQc",
        "outputId": "96be5bb5-86e6-4b22-a22f-c44246cb5adf"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Once', 'there', 'lived', 'a', 'greedy', 'man', 'in', 'a', 'small', 'town', '.', '(', 'He', 'was', 'very', 'rich', ',', 'and', 'he', 'loved', 'gold', 'and', 'all', 'things', 'fancy', '.', 'But', 'he', 'loved', 'his', 'daughter', 'more', 'than', 'anything', '.', 'One', 'day', ',', 'he', 'chanced', 'upon', 'a', 'fairy', '.', 'The', 'fairy', '’', 's', 'hair', 'was', 'caught', 'in', 'a', 'few', 'tree', 'branches', '.', 'He', 'helped', 'her', 'out', ',', 'but', 'as', 'his', 'greediness', 'took', 'over', ',', 'he', 'realised', 'that', 'he', 'had', 'an', 'opportunity', 'to', 'become', 'richer', 'by', 'asking', 'for', 'a', 'wish', 'in', 'return', '(', 'by', 'helping', 'her', 'out', ')', '.', 'The', 'fairy', 'granted', 'him', 'a', 'wish', '.', 'He', 'said', ',', '“', 'All', 'that', 'I', 'touch', 'should', 'turn', 'to', 'gold.', '”', 'And', 'his', 'wish', 'was', 'granted', 'by', 'the', 'grateful', 'fairy', '.']\n",
            "Sentence after Lematization :  Oncetherelivedagreedymaninasmalltown.(Hewaveryrich,andhelovedgoldandallthingfancy.Buthelovedhisdaughtermorethananything.Oneday,hechanceduponafairy.Thefairy’shairwacaughtinafewtreebranch.Hehelpedherout,butahisgreedinesstookover,herealisedthathehadanopportunitytobecomericherbyaskingforawishinreturn(byhelpingherout).Thefairygrantedhimawish.Hesaid,“AllthatItouchshouldturntogold.”Andhiswishwagrantedbythegratefulfairy.\n"
          ]
        }
      ]
    }
  ]
}